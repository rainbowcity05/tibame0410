{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCVmUFkd/aO72W9b6zJWXZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rainbowcity05/tibame0410/blob/main/tibame0422.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMwAxjjiUTts",
        "outputId": "86dac81b-1d40-4432-f5b1-50c28c1ea43a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page:1\n",
            "page:2\n",
            "page:3\n",
            "page:4\n",
            "page:5\n",
            "page:6\n",
            "page:7\n",
            "page:8\n",
            "page:9\n",
            "page:10\n"
          ]
        }
      ],
      "source": [
        "import urllib.request as req\n",
        "import bs4 as bs\n",
        "import pandas as pd\n",
        "table = []\n",
        "\n",
        "for i in range(10):\n",
        "  page = i + 1\n",
        "  print(\"page:{}\".format(page))\n",
        "  url = \"https://tabelog.com/tw/okinawa/rstLst/sweets/{}/?SrtT=rt\".format(page)\n",
        "  resp = req.urlopen(url)\n",
        "  content = resp.read()\n",
        "  html = bs.BeautifulSoup(content)\n",
        "\n",
        "  rs =html.find_all(\"div\",{\"class\":\"list-rst__contents\"})\n",
        "  for r in rs:\n",
        "    name = r.find(\"a\",{\"class\":\"list-rst__rst-name-target\"})\n",
        "    name_text = name.text\n",
        "    area_genre = r.find(\"div\",{\"class\":\"list-rst__area-genre\"})\n",
        "    area_genre_text = area_genre.text.strip()\n",
        "    area_genre_text_split = area_genre_text.split(\" / \")\n",
        "    if len(area_genre_text_split) == 1:\n",
        "      area_text, genre_text = \"\", area_genre_text_split[0],\n",
        "    else:\n",
        "      area_text, genre_text = area_genre_text_split[0], area_genre_text_split[1]\n",
        "    rating = r.find(\"span\",{\"class\":\"c-rating__val\"})\n",
        "    rating_text = rating.text.strip()\n",
        "    dinner, lunch = r.find_all(\"span\",{\"class\":\"c-rating-v3__val\"})\n",
        "\n",
        "    data = {\n",
        "      \"餐廳名稱\" : name_text,\n",
        "      \"評分\" : rating_text,\n",
        "      \"地區\" : area_text,\n",
        "      \"種類\" : genre_text,\n",
        "      \"晚餐價格\" : dinner.text,\n",
        "      \"午餐價格\" : lunch.text\n",
        "    }\n",
        "    table.append(data)\n",
        "\n",
        "df = pd.DataFrame(table)\n",
        "df.to_csv(\"tabelog.csv\",encoding=\"utf-8\",index=False)\n",
        "\n",
        "\n",
        "    # print(name_text)\n",
        "    # print(rating_text)\n",
        "    # print(area_text)\n",
        "    # print(genre_text)\n",
        "    # print(dinner.text)\n",
        "    # print(lunch.text)\n",
        "    # print(\"-\"*20)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request as req\n",
        "import bs4 as bs\n",
        "import json\n",
        "\n",
        "url = \"https://www.ptt.cc/bbs/Beauty/M.1745216140.A.52E.html\"\n",
        "r = req.Request(url)\n",
        "r.add_header(\"User-Agent\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/10\")\n",
        "resp = req.urlopen(r)\n",
        "html = bs.BeautifulSoup(resp.read())\n",
        "\n",
        "# meta process\n",
        "metas = html.find_all(\"span\", {\"class\":\"article-meta-value\"})\n",
        "post_id = metas[0].text\n",
        "board_name = metas[1].text\n",
        "post_title = metas[2].text\n",
        "post_time = metas[3].text\n",
        "\n",
        "# push process\n",
        "push_list = []\n",
        "pushes = html.find_all(\"div\", {\"class\":\"push\"})\n",
        "for push in pushes:\n",
        "    push_meta = push.find_all(\"span\")\n",
        "    p_type = push_meta[0].text\n",
        "    if \"推\" in p_type:\n",
        "        p_type = 1\n",
        "    elif \"噓\" in p_type:\n",
        "        p_type = -1\n",
        "    else:\n",
        "        p_type = 0\n",
        "    p_id = push_meta[1].text\n",
        "    p_text = push_meta[2].text.replace(\": \", \"\")\n",
        "    p_ipanddate = push_meta[3].text.strip()\n",
        "    p_dict = {\n",
        "        \"id\":p_id,\n",
        "        \"type\":p_type,\n",
        "        \"text\":p_text,\n",
        "        \"ip/date\":p_ipanddate\n",
        "    }\n",
        "    push_list.append(p_dict)\n",
        "\n",
        "row = {\n",
        "    \"作者\":post_id,\n",
        "    \"標題\":post_title,\n",
        "    \"時間\":post_time,\n",
        "    \"看板\":board_name,\n",
        "    \"推噓文\":push_list\n",
        "}\n",
        "\n",
        "fn = url.split(\"/\")[-1].replace(\".html\", \".json\")\n",
        "with open(fn, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(row, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "3MpKvJEYVjl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request as req\n",
        "import bs4 as bs\n",
        "import json\n",
        "\n",
        "url = \"https://www.ptt.cc/bbs/Beauty/M.1745400594.A.909.html\"\n",
        "r = req.Request(url)\n",
        "r.add_header\n",
        "\n"
      ],
      "metadata": {
        "id": "8Ceiw4e5XQpJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 內文: extract() 命令消失\n",
        "# 所以把main-content區塊裡面的其他的div都消失\n",
        "import urllib.request as req\n",
        "import bs4 as bs\n",
        "\n",
        "url = \"https://www.ptt.cc/bbs/Beauty/M.1745215157.A.CAA.html\"\n",
        "r = req.Request(url)\n",
        "r.add_header(\"User-Agent\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/10\")\n",
        "resp = req.urlopen(r)\n",
        "html = bs.BeautifulSoup(resp.read())\n",
        "\n",
        "\n",
        "main_content = html.find(\"div\", {\"id\":\"main-content\"})\n",
        "other_div = main_content.find_all(\"div\")\n",
        "for other in other_div:\n",
        "    other.extract()\n",
        "print(main_content.text)"
      ],
      "metadata": {
        "id": "A-z8sSvLVosW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}